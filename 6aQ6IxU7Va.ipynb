{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to a competition powered by AutoDSC for Data Science Challenges! By Prof. Manoel Gadi!\n",
    "\n",
    "PLEASE DO NOT RENAME THIS FILE!\n",
    "\n",
    "\n",
    "Simply run this code and start competing today in the competion: 6aQ6IxU7Va\n",
    "\n",
    "6aQ6IxU7Va details:\n",
    " - Description / Descripción: FRAUD MODELLING CHALLENGE - Predict which Credit Card Application is legitimate and which belongs to a fraudster instead.\n",
    " - Maximum number of daily attempts / Número máximo de intentos diarios: 10000\n",
    " - Creation date / Fecha de creación: 2020-06-10 11:36:52\n",
    " - Starting date / Fecha de inicio: 2022-05-11 00:00:00\n",
    " - Ending date / Fecha de fin: 2022-05-27 23:59:00\n",
    " - Minimum time between prediction submissions / Tiempo mínimo entre envíos de predicciones: 30\n",
    "\n",
    "Of couse, to win the competition you should improve the starting model! So let's get to work!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTING LIBRARIES...\n",
      "LOADING DATASETS...\n"
     ]
    }
   ],
   "source": [
    "print (\"IMPORTING LIBRARIES...\")\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "print (\"LOADING DATASETS...\")\n",
    "try: # reading train csv from local file\n",
    "    df_train = pd.read_csv(\"mfalonso__6aQ6IxU7Va__train.csv\")\n",
    "    df_train.head()\n",
    "except: # reading train csv from the internet if it is the first time\n",
    "    import urllib\n",
    "    csv_train = urllib.request.urlopen(\"http://manoelutad.pythonanywhere.com/static/uploads/mfalonso__6aQ6IxU7Va__train.csv\")\n",
    "    csv_train_content = csv_train.read()\n",
    "    with open(\"mfalonso__6aQ6IxU7Va__train.csv\", 'wb') as f:\n",
    "            f.write(csv_train_content)\n",
    "    df_train = pd.read_csv(\"mfalonso__6aQ6IxU7Va__train.csv\")\n",
    "\n",
    "    \n",
    "try: # reading test csv from local file\n",
    "    df_test = pd.read_csv(\"mfalonso__6aQ6IxU7Va__test.csv\")\n",
    "    df_test.head()\n",
    "except: # reading test csv from the internet if it is the first time\n",
    "    import urllib\n",
    "    csv_test = urllib.request.urlopen(\"http://manoelutad.pythonanywhere.com/static/uploads/mfalonso__6aQ6IxU7Va__test.csv\")\n",
    "    csv_test_content = csv_test.read()\n",
    "    with open(\"mfalonso__6aQ6IxU7Va__test.csv\", 'wb') as f:\n",
    "            f.write(csv_test_content)\n",
    "    df_test = pd.read_csv(\"mfalonso__6aQ6IxU7Va__test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'ib_var_1', 'ib_var_2', 'ib_var_3', 'ib_var_4',\n",
       "       'ib_var_5', 'ib_var_6', 'ib_var_7', 'ib_var_8', 'ib_var_9', 'ib_var_10',\n",
       "       'ib_var_11', 'ib_var_12', 'ib_var_13', 'ib_var_14', 'ib_var_15',\n",
       "       'ib_var_16', 'ib_var_17', 'ib_var_18', 'ib_var_19', 'ib_var_20',\n",
       "       'ib_var_21', 'icn_var_22', 'icn_var_23', 'icn_var_24', 'ico_var_25',\n",
       "       'ico_var_26', 'ico_var_27', 'ico_var_28', 'ico_var_29', 'ico_var_30',\n",
       "       'ico_var_31', 'ico_var_32', 'ico_var_33', 'ico_var_34', 'ico_var_35',\n",
       "       'ico_var_36', 'ico_var_37', 'ico_var_38', 'ico_var_39', 'ico_var_40',\n",
       "       'ico_var_41', 'ico_var_42', 'ico_var_43', 'ico_var_44', 'ico_var_45',\n",
       "       'ico_var_46', 'ico_var_47', 'ico_var_48', 'ico_var_49', 'ico_var_50',\n",
       "       'ico_var_51', 'ico_var_52', 'ico_var_53', 'ico_var_54', 'ico_var_55',\n",
       "       'ico_var_56', 'ico_var_57', 'ico_var_58', 'ico_var_59', 'ico_var_60',\n",
       "       'ico_var_61', 'ico_var_62', 'ico_var_63', 'ico_var_64', 'if_var_65',\n",
       "       'if_var_66', 'if_var_67', 'if_var_68', 'if_var_69', 'if_var_70',\n",
       "       'if_var_71', 'if_var_72', 'if_var_73', 'if_var_74', 'if_var_75',\n",
       "       'if_var_76', 'if_var_77', 'if_var_78', 'if_var_79', 'if_var_80',\n",
       "       'if_var_81', 'ob_target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'ib_var_1', 'ib_var_2', 'ib_var_3', 'ib_var_4',\n",
       "       'ib_var_5', 'ib_var_6', 'ib_var_7', 'ib_var_8', 'ib_var_9', 'ib_var_10',\n",
       "       'ib_var_11', 'ib_var_12', 'ib_var_13', 'ib_var_14', 'ib_var_15',\n",
       "       'ib_var_16', 'ib_var_17', 'ib_var_18', 'ib_var_19', 'ib_var_20',\n",
       "       'ib_var_21', 'icn_var_22', 'icn_var_23', 'icn_var_24', 'ico_var_25',\n",
       "       'ico_var_26', 'ico_var_27', 'ico_var_28', 'ico_var_29', 'ico_var_30',\n",
       "       'ico_var_31', 'ico_var_32', 'ico_var_33', 'ico_var_34', 'ico_var_35',\n",
       "       'ico_var_36', 'ico_var_37', 'ico_var_38', 'ico_var_39', 'ico_var_40',\n",
       "       'ico_var_41', 'ico_var_42', 'ico_var_43', 'ico_var_44', 'ico_var_45',\n",
       "       'ico_var_46', 'ico_var_47', 'ico_var_48', 'ico_var_49', 'ico_var_50',\n",
       "       'ico_var_51', 'ico_var_52', 'ico_var_53', 'ico_var_54', 'ico_var_55',\n",
       "       'ico_var_56', 'ico_var_57', 'ico_var_58', 'ico_var_59', 'ico_var_60',\n",
       "       'ico_var_61', 'ico_var_62', 'ico_var_63', 'ico_var_64', 'if_var_65',\n",
       "       'if_var_66', 'if_var_67', 'if_var_68', 'if_var_69', 'if_var_70',\n",
       "       'if_var_71', 'if_var_72', 'if_var_73', 'if_var_74', 'if_var_75',\n",
       "       'if_var_76', 'if_var_77', 'if_var_78', 'if_var_79', 'if_var_80',\n",
       "       'if_var_81', 'contract_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: DOING MY TRANSFORMATIONS...\n"
     ]
    }
   ],
   "source": [
    "print (\"STEP 1: DOING MY TRANSFORMATIONS...\")\n",
    "df_train = df_train.fillna(0)\n",
    "df_test = df_test.fillna(0)\n",
    "df_test = df_test.drop(columns=[\"contract_date\", 'Unnamed: 0']) #removing useless columns\n",
    "df_train = df_train.drop(columns=[\"Unnamed: 0\"]) #removing more useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2967, 82)\n",
      "(864, 83)\n"
     ]
    }
   ],
   "source": [
    "#making sure train/test have the same number of features\n",
    "print(df_test.shape)\n",
    "print(df_train.shape) #train set has one feature more because the target variable is included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: SELECTING CHARACTERISTICS TO ENTER INTO THE MODEL...\n"
     ]
    }
   ],
   "source": [
    "print (\"STEP 2: SELECTING CHARACTERISTICS TO ENTER INTO THE MODEL...\")\n",
    "def get_specific_columns(df, data_types, to_ignore = list(), ignore_target = False):\n",
    "    columns = df.select_dtypes(include=data_types).columns\n",
    "    if ignore_target:\n",
    "        columns = filter(lambda x: x not in to_ignore, list(columns))\n",
    "    return list(columns)\n",
    "\n",
    "output_var = df_train.columns[-1]\n",
    "in_model = get_specific_columns(df_train, [\"float64\", \"int64\"], [output_var], ignore_target = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for imbalanace, correcting it & trying out the model\n",
    "* Fraud cases only represent ~10% of total cases\n",
    "* Upsampling managed to increase model accuracy, here is the code to how I did it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898148\n",
       "1    0.101852\n",
       "Name: ob_target, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking percentage of fraud vs non-fraud cases\n",
    "df_train['ob_target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    776\n",
       "1     88\n",
       "Name: ob_target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking real values\n",
    "df_train['ob_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    776\n",
       "1    776\n",
       "Name: ob_target, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing resampling tool\n",
    "from sklearn.utils import resample\n",
    "\n",
    "#separating majority and minority classes\n",
    "df_majority = df_train[df_train.ob_target==0]\n",
    "df_minority = df_train[df_train.ob_target==1]\n",
    " \n",
    "#upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=776,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "#combine majority class with upsampled minority class\n",
    "data_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    " \n",
    "#display new class counts\n",
    "data_upsampled.ob_target.value_counts()\n",
    "\n",
    "#assigning balanced dataset to train set\n",
    "df_train = data_upsampled\n",
    "\n",
    "#checking if balance was properly corrected \n",
    "df_train['ob_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing classifiers to try out\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 3: DEVELOPING THE MODEL...\n"
     ]
    }
   ],
   "source": [
    "print (\"STEP 3: DEVELOPING THE MODEL...\")\n",
    "X_train = df_train[in_model]\n",
    "y_train = df_train[output_var]\n",
    "X_test = df_test[in_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10000, oob_score=True, \n",
    "                             random_state=123 ,max_features='log2', \n",
    "                             bootstrap = 'True', min_samples_split = 2, \n",
    "                             min_samples_leaf = 1, criterion = 'entropy', n_jobs=5) \n",
    "scaler = StandardScaler()\n",
    "\n",
    "pipe = Pipeline(steps=[('scaler', scaler),\n",
    "                       ('clf', clf)])\n",
    "\n",
    "#selection = SelectKBest(chi2, k=25)\n",
    "#pca = PCA(n_components=20) \n",
    "\n",
    "#('pca', pca)\n",
    "#('scaler', scaler),\n",
    "#('selection', selection)\n",
    "#('poly', PolynomialFeatures(degree=1))\n",
    "\n",
    "fitted_model = pipe.fit(X_train, y_train)\n",
    "pred_train = fitted_model.predict_proba(X_train)[:,1]\n",
    "pred_test  = fitted_model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 4: ASSESSING THE MODEL...\n",
      "GINI DEVELOPMENT= 1.0\n"
     ]
    }
   ],
   "source": [
    "print (\"STEP 4: ASSESSING THE MODEL...\")\n",
    "# CALCULATING GINI PERFORMANCE ON DEVELOPMENT SAMPLE\n",
    "from sklearn.metrics import roc_auc_score\n",
    "gini_score = 2*roc_auc_score(y_train, pred_train)-1\n",
    "print (\"GINI DEVELOPMENT=\", gini_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHAT IS GINI?\n",
    "* watch this video for reference: https://youtu.be/MiBUBVUC8kE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 5: SUBMITTING THE RESULTS... DO NOT CHANGE THIS PART!\n",
      "RESULT SUBMISSION:  Competition / competición: 6aQ6IxU7Va - gini = 0.5191683841809998\n"
     ]
    }
   ],
   "source": [
    "print (\"STEP 5: SUBMITTING THE RESULTS... DO NOT CHANGE THIS PART!\")\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "df_test['pred'] = pred_test\n",
    "df_test['id'] = df_test.iloc[:,0]\n",
    "df_test_tosend = df_test[['id','pred']]\n",
    "\n",
    "filename = \"df_test_tosend.csv\"\n",
    "df_test_tosend.to_csv(filename, sep=',')\n",
    "url = 'http://manoelutad.pythonanywhere.com/uploadpredictions/6aQ6IxU7Va'\n",
    "files = {'file': (filename, open(filename, 'rb')),\n",
    "         'ipynbcode': ('6aQ6IxU7Va.ipynb', open('6aQ6IxU7Va.ipynb', 'rb'))}\n",
    "\n",
    "\n",
    "#rsub = requests.post(url, files=files)\n",
    "rsub = requests.post(url, files=files, auth=HTTPBasicAuth(\"emiliano.delia\", \"sha256$Il35mIU2$a50e631727b33b754a579f1cd5de776b565cacfcffe13d7efb0f0e3d48219b61\"))\n",
    "resp_str = str(rsub.text)\n",
    "print (\"RESULT SUBMISSION: \", resp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
